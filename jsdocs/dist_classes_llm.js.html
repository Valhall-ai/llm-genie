<!DOCTYPE html><html lang="en" style="font-size:16px"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Source: dist/classes/llm.js</title><!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]--><script src="scripts/third-party/hljs.js" defer="defer"></script><script src="scripts/third-party/hljs-line-num.js" defer="defer"></script><script src="scripts/third-party/popper.js" defer="defer"></script><script src="scripts/third-party/tippy.js" defer="defer"></script><script src="scripts/third-party/tocbot.min.js"></script><script>var baseURL="/",locationPathname="",baseURL=(locationPathname=document.location.pathname).substr(0,locationPathname.lastIndexOf("/")+1)</script><link rel="stylesheet" href="styles/clean-jsdoc-theme.min.css"><svg aria-hidden="true" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" style="display:none"><defs><symbol id="copy-icon" viewbox="0 0 488.3 488.3"><g><path d="M314.25,85.4h-227c-21.3,0-38.6,17.3-38.6,38.6v325.7c0,21.3,17.3,38.6,38.6,38.6h227c21.3,0,38.6-17.3,38.6-38.6V124    C352.75,102.7,335.45,85.4,314.25,85.4z M325.75,449.6c0,6.4-5.2,11.6-11.6,11.6h-227c-6.4,0-11.6-5.2-11.6-11.6V124    c0-6.4,5.2-11.6,11.6-11.6h227c6.4,0,11.6,5.2,11.6,11.6V449.6z"/><path d="M401.05,0h-227c-21.3,0-38.6,17.3-38.6,38.6c0,7.5,6,13.5,13.5,13.5s13.5-6,13.5-13.5c0-6.4,5.2-11.6,11.6-11.6h227    c6.4,0,11.6,5.2,11.6,11.6v325.7c0,6.4-5.2,11.6-11.6,11.6c-7.5,0-13.5,6-13.5,13.5s6,13.5,13.5,13.5c21.3,0,38.6-17.3,38.6-38.6    V38.6C439.65,17.3,422.35,0,401.05,0z"/></g></symbol><symbol id="search-icon" viewBox="0 0 512 512"><g><g><path d="M225.474,0C101.151,0,0,101.151,0,225.474c0,124.33,101.151,225.474,225.474,225.474    c124.33,0,225.474-101.144,225.474-225.474C450.948,101.151,349.804,0,225.474,0z M225.474,409.323    c-101.373,0-183.848-82.475-183.848-183.848S124.101,41.626,225.474,41.626s183.848,82.475,183.848,183.848    S326.847,409.323,225.474,409.323z"/></g></g><g><g><path d="M505.902,476.472L386.574,357.144c-8.131-8.131-21.299-8.131-29.43,0c-8.131,8.124-8.131,21.306,0,29.43l119.328,119.328    c4.065,4.065,9.387,6.098,14.715,6.098c5.321,0,10.649-2.033,14.715-6.098C514.033,497.778,514.033,484.596,505.902,476.472z"/></g></g></symbol><symbol id="font-size-icon" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0z"/><path d="M11.246 15H4.754l-2 5H.6L7 4h2l6.4 16h-2.154l-2-5zm-.8-2L8 6.885 5.554 13h4.892zM21 12.535V12h2v8h-2v-.535a4 4 0 1 1 0-6.93zM19 18a2 2 0 1 0 0-4 2 2 0 0 0 0 4z"/></symbol><symbol id="add-icon" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0z"/><path d="M11 11V5h2v6h6v2h-6v6h-2v-6H5v-2z"/></symbol><symbol id="minus-icon" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0z"/><path d="M5 11h14v2H5z"/></symbol><symbol id="dark-theme-icon" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0z"/><path d="M10 7a7 7 0 0 0 12 4.9v.1c0 5.523-4.477 10-10 10S2 17.523 2 12 6.477 2 12 2h.1A6.979 6.979 0 0 0 10 7zm-6 5a8 8 0 0 0 15.062 3.762A9 9 0 0 1 8.238 4.938 7.999 7.999 0 0 0 4 12z"/></symbol><symbol id="light-theme-icon" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0z"/><path d="M12 18a6 6 0 1 1 0-12 6 6 0 0 1 0 12zm0-2a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM11 1h2v3h-2V1zm0 19h2v3h-2v-3zM3.515 4.929l1.414-1.414L7.05 5.636 5.636 7.05 3.515 4.93zM16.95 18.364l1.414-1.414 2.121 2.121-1.414 1.414-2.121-2.121zm2.121-14.85l1.414 1.415-2.121 2.121-1.414-1.414 2.121-2.121zM5.636 16.95l1.414 1.414-2.121 2.121-1.414-1.414 2.121-2.121zM23 11v2h-3v-2h3zM4 11v2H1v-2h3z"/></symbol><symbol id="reset-icon" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0z"/><path d="M18.537 19.567A9.961 9.961 0 0 1 12 22C6.477 22 2 17.523 2 12S6.477 2 12 2s10 4.477 10 10c0 2.136-.67 4.116-1.81 5.74L17 12h3a8 8 0 1 0-2.46 5.772l.997 1.795z"/></symbol><symbol id="down-icon" viewBox="0 0 16 16"><path fill-rule="evenodd" clip-rule="evenodd" d="M12.7803 6.21967C13.0732 6.51256 13.0732 6.98744 12.7803 7.28033L8.53033 11.5303C8.23744 11.8232 7.76256 11.8232 7.46967 11.5303L3.21967 7.28033C2.92678 6.98744 2.92678 6.51256 3.21967 6.21967C3.51256 5.92678 3.98744 5.92678 4.28033 6.21967L8 9.93934L11.7197 6.21967C12.0126 5.92678 12.4874 5.92678 12.7803 6.21967Z"></path></symbol><symbol id="codepen-icon" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0z"/><path d="M16.5 13.202L13 15.535v3.596L19.197 15 16.5 13.202zM14.697 12L12 10.202 9.303 12 12 13.798 14.697 12zM20 10.869L18.303 12 20 13.131V10.87zM19.197 9L13 4.869v3.596l3.5 2.333L19.197 9zM7.5 10.798L11 8.465V4.869L4.803 9 7.5 10.798zM4.803 15L11 19.131v-3.596l-3.5-2.333L4.803 15zM4 13.131L5.697 12 4 10.869v2.262zM2 9a1 1 0 0 1 .445-.832l9-6a1 1 0 0 1 1.11 0l9 6A1 1 0 0 1 22 9v6a1 1 0 0 1-.445.832l-9 6a1 1 0 0 1-1.11 0l-9-6A1 1 0 0 1 2 15V9z"/></symbol><symbol id="close-icon" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0z"/><path d="M12 10.586l4.95-4.95 1.414 1.414-4.95 4.95 4.95 4.95-1.414 1.414-4.95-4.95-4.95 4.95-1.414-1.414 4.95-4.95-4.95-4.95L7.05 5.636z"/></symbol><symbol id="menu-icon" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0z"/><path d="M3 4h18v2H3V4zm0 7h18v2H3v-2zm0 7h18v2H3v-2z"/></symbol></defs></svg></head><body class="dark" data-theme="dark"><div class="sidebar-container"><div class="sidebar" id="sidebar"><a href="index.html" class="sidebar-title">LLM-Genie</a><div class="sidebar-items-container"><div class="sidebar-section-title with-arrow" data-isopen="false" id="4onA_09XbbvBLu6T03j-k"><div>Classes</div><svg><use xlink:href="#down-icon"></use></svg></div><div class="sidebar-section-children-container"><div class="sidebar-section-children"><a href="LLMGenie.html">LLMGenie</a></div></div></div></div></div><div class="navbar-container" id="VuAckcnZhf"><nav class="navbar"><div class="navbar-left-items"></div><div class="navbar-right-items"><div class="navbar-right-item"><button class="icon-button search-button" aria-label="open-search"><svg><use xlink:href="#search-icon"></use></svg></button></div><div class="navbar-right-item"><button class="icon-button theme-toggle" aria-label="toggle-theme"><svg><use class="theme-svg-use" xlink:href="#light-theme-icon"></use></svg></button></div><div class="navbar-right-item"><button class="icon-button font-size" aria-label="change-font-size"><svg><use xlink:href="#font-size-icon"></use></svg></button></div></div><nav></nav></nav></div><div class="toc-container"><div class="toc-content"><span class="bold">On this page</span><div id="eed4d2a0bfd64539bb9df78095dec881"></div></div></div><div class="body-wrapper"><div class="main-content"><div class="main-wrapper"><section id="source-page" class="source-page"><header><h1 id="title" class="has-anchor">dist_classes_llm.js</h1></header><article><pre class="prettyprint source lang-js"><code>"use strict";
var __createBinding = (this &amp;&amp; this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this &amp;&amp; this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this &amp;&amp; this.__importStar) || function (mod) {
    if (mod &amp;&amp; mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" &amp;&amp; Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __awaiter = (this &amp;&amp; this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __rest = (this &amp;&amp; this.__rest) || function (s, e) {
    var t = {};
    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) &amp;&amp; e.indexOf(p) &lt; 0)
        t[p] = s[p];
    if (s != null &amp;&amp; typeof Object.getOwnPropertySymbols === "function")
        for (var i = 0, p = Object.getOwnPropertySymbols(s); i &lt; p.length; i++) {
            if (e.indexOf(p[i]) &lt; 0 &amp;&amp; Object.prototype.propertyIsEnumerable.call(s, p[i]))
                t[p[i]] = s[p[i]];
        }
    return t;
};
var __importDefault = (this &amp;&amp; this.__importDefault) || function (mod) {
    return (mod &amp;&amp; mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.LLMGenie = void 0;
const gpt_3_encoder_1 = require("gpt-3-encoder");
const dotenv = __importStar(require("dotenv"));
const promises_1 = require("timers/promises");
const format_validator_1 = __importDefault(require("../classes/format-validator"));
dotenv.config();
const validator = new format_validator_1.default();
function isValidList(obj) {
    return !!obj.list;
}
function isValidatorResultWithStringList(obj) {
    return obj &amp;&amp; typeof obj.list !== "undefined";
}
function createChatCompletion(request, queryFunc, maxRetries = 5, initialDelay = 1000, maxDelay = 60000) {
    return __awaiter(this, void 0, void 0, function* () {
        let delay = initialDelay;
        for (let attempt = 1; attempt &lt;= maxRetries; attempt++) {
            try {
                const response = yield queryFunc(request);
                return response;
            }
            catch (error) {
                const jitter = Math.random() * 0.2 * delay;
                const waitTime = Math.min(delay + jitter, maxDelay);
                if (attempt &lt; maxRetries) {
                    console.log(`Retrying GPT query ( ${waitTime} ms delay... ), Error:`, error);
                    yield (0, promises_1.setTimeout)(waitTime);
                    console.log("done waiting");
                    delay *= 2;
                }
                else {
                    throw new Error(`Max retries reached (${maxRetries}). Failed to create chat completion.`);
                }
            }
        }
    });
}
const trackers = [];
let uniqueId = 0;
class Tracker {
    constructor() {
        trackers.push(this);
        this.id = uniqueId;
        uniqueId++;
        this.nodes = [];
    }
    addNode(name, details) {
        this.nodes.push(Object.assign({ name, timestamp: new Date().getTime() }, (details ? { details } : {})));
    }
}
/**
 * A class for interacting with the GPT.
 */
class LLMGenie {
    /**
     * Constructs a GPT instance.
     */
    constructor(settings) {
        this.jobs = [];
        this.maxAttempts = 10;
        this.currentQueryCount = 0;
        this.maxQueryCount = 250;
        this.queryFunc = settings.queryFunc;
        // Store model configuration
        this.modelConfig = settings.modelConfig;
    }
    /**
     * Query the GPT model with given settings and tracker returns the generated results.
     * @param {Object} settings
     * @param {Tracker?} tracker
     * @returns {Promise&lt;Array&lt;String> | string>}
     */
    query(settings = { primaryContent: false }, tracker) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!tracker) {
                tracker = new Tracker();
            }
            const defaults = Object.assign({ debug: true, systemPrompt: false, summarize: false, topP: 1, maxQueryResponseTokens: false, improve: {
                    passes: 0,
                    maintainLength: false,
                }, preContent: "", postContent: "" }, settings);
            console.log("query defaults", defaults);
            let preContent = defaults.preContent;
            if (!preContent)
                preContent = "";
            if (preContent.length > 0)
                preContent += "\n";
            let primaryContent = defaults.primaryContent;
            let postContent = defaults.postContent;
            if (!postContent)
                postContent = "";
            if (postContent.length > 0)
                postContent = "\n" + postContent;
            this.currentQueryCount++;
            if (this.currentQueryCount > this.maxQueryCount)
                throw new Error("Safety error: currentQueryCount > maxQueryCount");
            // Use the modelConfig provided by the user
            const maxModelTokens = this.modelConfig.maxModelTokens;
            let maxQueryResponseTokens;
            if (defaults.maxQueryResponseTokens)
                maxQueryResponseTokens = Math.min(maxModelTokens, defaults.maxQueryResponseTokens);
            else
                maxQueryResponseTokens = Math.round(maxModelTokens / 2);
            let chunks = [];
            let preContentTokens;
            if (!preContent || preContent.length === 0)
                preContentTokens = 0;
            else
                preContentTokens = (0, gpt_3_encoder_1.encode)(preContent).length;
            let primaryContentTokens;
            if (!primaryContent || primaryContent.length === 0)
                throw new Error(`primaryContent must be a non-empty string: ${primaryContent}`);
            else
                primaryContentTokens = (0, gpt_3_encoder_1.encode)(primaryContent).length;
            let postContentTokens;
            if (!postContent || postContent.length === 0)
                postContentTokens = 0;
            else
                postContentTokens = (0, gpt_3_encoder_1.encode)(postContent).length;
            let allTokens = preContentTokens + primaryContentTokens + postContentTokens;
            let usedTokens = allTokens + maxQueryResponseTokens;
            let currentChunkTokens = 0;
            let chunkStartIndex = 0;
            for (let i = 0; i &lt; primaryContent.length; i++) {
                currentChunkTokens =
                    (0, gpt_3_encoder_1.encode)(primaryContent.slice(chunkStartIndex, i)).length +
                        preContentTokens +
                        postContentTokens;
                if (currentChunkTokens + maxQueryResponseTokens > maxModelTokens ||
                    i === primaryContent.length - 1) {
                    let chunk = primaryContent.slice(chunkStartIndex, i);
                    if (chunkStartIndex > 0) {
                        chunk += " [text truncated]\n";
                    }
                    let chunkWithContent = "";
                    if (preContent.length > 0)
                        chunkWithContent += preContent + "\n";
                    chunkWithContent += chunk;
                    if (postContent.length > 0)
                        chunkWithContent += postContent;
                    chunks.push(chunkWithContent);
                    chunkStartIndex = i;
                }
            }
            const chatChunks = [];
            for (let i = 0; i &lt; chunks.length; i++) {
                const chunk = chunks[i];
                chatChunks.push({ role: "user", content: chunk });
            }
            console.log(`GPT Query:\n\nsystemPrompt (\n\n${defaults.systemPrompt}\n\n)\n\npreContent (\n\n${preContent}\n\n)\n\nprimaryContent (\n\n${primaryContent}\n\n)\n\npostContent (\n\n${postContent}\n\n)\n\n ...breakdown: usedTokens:`, usedTokens, "\nallTokens:", `${allTokens} = preContentTokens (${preContentTokens}) + primaryContentTokens (${primaryContentTokens}) + postContentTokens (${postContentTokens})`, "\nmaxModelTokens:", maxModelTokens, "\nmaxQueryResponseTokens:", maxQueryResponseTokens, "\nchunks:", chunks);
            const results = [];
            for (let i = 0; i &lt; chatChunks.length; i++) {
                const chunk = chatChunks[i];
                const messages = [];
                if (defaults.systemPrompt)
                    messages.push({ role: "system", content: defaults.systemPrompt });
                messages.push(chunk);
                const request = {
                    messages: messages,
                    max_tokens: maxQueryResponseTokens,
                    temperature: defaults.temperature,
                };
                if (defaults.topP)
                    request["top_p"] = defaults.topP;
                if (defaults.maxQueryResponseTokens)
                    request["max_tokens"] = defaults.maxQueryResponseTokens;
                if (defaults.temperature)
                    request["temperature"] = defaults.temperature;
                const response = yield createChatCompletion(request, this.queryFunc);
                console.log("response", response);
                results.push(response.data.choices[0].message.content);
                tracker.addNode("query", {
                    usage: response.data.usage,
                });
            }
            if (defaults.improve.passes > 0) {
                console.log("Fact checking...");
                for (let i = 0; i &lt; results.length; i++) {
                    const result = results[i];
                    console.log(`Fact check of result:\n\n${result}`);
                    const revised = yield this.improve({
                        input: result,
                        passes: defaults.improve.passes,
                        maintainLength: defaults.improve.maintainLength,
                    });
                    console.log(`Revision:\n\n${revised}`);
                }
            }
            if (defaults.summarize) {
                const result = yield this.summarizeCompletionSet(results);
                console.log(`Summarized query result:\n${result}`);
                return result;
            }
            console.log(`Raw query results:`, results);
            return results;
        });
    }
    /**
     * Summarizes the input completion set.
     * @param {Array&lt;string>} completionSet
     * @param {boolean} polish
     * @param {Tracker} tracker
     * @returns {Promise&lt;string>}
     */
    summarizeCompletionSet(completionSet, polish = false, tracker) {
        return __awaiter(this, void 0, void 0, function* () {
            let summary;
            if (!tracker) {
                tracker = new Tracker();
            }
            tracker.addNode("summarizeCompletionSet");
            if (completionSet.length > 1) {
                let combinationPrompt = "The following texts are responses based on chunks of the same input text. Combine the texts into a single, overarching summary, broken into paragraphs. Preserve as many details as possible and even elaborate on any vague concepts:\n\n";
                let content = "";
                completionSet.forEach((completion) => {
                    content += completion + "\n\n";
                });
                const combinationResult = yield this.query({
                    primaryContent: content,
                    systemPrompt: combinationPrompt,
                });
                // Wrap single string result to an Array.
                const combinationCompletions = Array.isArray(combinationResult)
                    ? combinationResult
                    : [combinationResult];
                summary = combinationCompletions[0];
                if (polish) {
                    let polishPrompt = "Rephrase the following text without losing any detail, but with elaboration and professional wording.";
                    let polishedCompletions = yield this.query({
                        primaryContent: summary,
                        systemPrompt: polishPrompt,
                    });
                    summary = polishedCompletions[0];
                }
                if (polish &amp;&amp; summary.length > 1500) {
                    const separationPrompt = `Break the following text into separate paragraphs and remove any duplicate or redundant information:\n\n`;
                    let separationCompletions = yield this.query({
                        primaryContent: summary,
                        systemPrompt: separationPrompt,
                    });
                    summary = separationCompletions[0];
                }
                // Recursive call if the result of this.query is longer than one item
                if (combinationCompletions.length > 1) {
                    summary = yield this.summarizeCompletionSet(combinationCompletions, polish);
                }
            }
            else {
                summary = completionSet[0];
            }
            return summary;
        });
    }
    /**
     * Query GPT model with given settings and tracker for valid output, returns the generated result.
     * @param {Object} settings
     * @param {Tracker} tracker
     * @returns {Promise&lt;ValidatorResult | Array&lt;any>>}
     */
    queryValid(settings, tracker) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!tracker) {
                tracker = new Tracker();
            }
            tracker.addNode("queryValid");
            const { preContent = false, postContent = false, maxQueryResponseTokens = false, constraintType = "numbered", debug = false } = settings, rest = __rest(settings, ["preContent", "postContent", "maxQueryResponseTokens", "constraintType", "debug"]);
            const receivedSettings = Object.assign({ preContent,
                postContent,
                maxQueryResponseTokens,
                constraintType,
                debug }, rest);
            if (receivedSettings.systemPrompt) {
                receivedSettings.systemPrompt += receivedSettings.precursorSystemPrompt;
            }
            else {
                receivedSettings.systemPrompt = receivedSettings.precursorSystemPrompt;
            }
            let attempts = 0;
            let validList = false;
            let response;
            while (!validList) {
                if (attempts > this.maxAttempts) {
                    throw new Error("Safety error: currentQueryCount > maxQueryCount");
                }
                attempts++;
                response = yield this.query(receivedSettings);
                validList = receivedSettings.validationFunc.call(validator, response[0], receivedSettings);
                if (!validList) {
                    validList = yield this.queryGuideConstraint(receivedSettings);
                }
            }
            if (validList &amp;&amp; receivedSettings.debug) {
                console.log(`Response:\n${response}\nwith options`, receivedSettings, `is valid:`, validList);
            }
            if (["numbered", "bulleted"].includes(receivedSettings.constraintType)) {
                if (isValidatorResultWithStringList(validList)) {
                    const list = validList.list;
                    return receivedSettings.singleChoice &amp;&amp; list &amp;&amp; list.length > 0
                        ? [list[0]]
                        : list || [];
                }
                return [];
            }
            else if (receivedSettings.constraintType === "boolean") {
                if (typeof validList === "boolean") {
                    return validList ? "yes" : "no";
                }
                return false;
            }
            else {
                return validList;
            }
        });
    }
    /**
     * Query GPT model in list format with given settings and tracker, returns the generated
     * result in a bulleted list.
     * @param {Object} settings
     * @param {Tracker} tracker
     * @returns {Promise&lt;Array&lt;string>>}
     */
    queryList(settings, tracker) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!tracker) {
                tracker = new Tracker();
            }
            tracker.addNode("queryList");
            const defaults = Object.assign({ constrainedChoices: false, debug: true }, settings);
            let constrainedChoicesPrompt = "";
            if (defaults.constrainedChoices) {
                constrainedChoicesPrompt +=
                    "Only the following choices are allowed in the bulleted list:\n";
                for (let i = 0; i &lt; defaults.constrainedChoices.length; i++) {
                    const choice = defaults.constrainedChoices[i];
                    constrainedChoicesPrompt += `- ${choice}\n`;
                }
                constrainedChoicesPrompt += "\n";
            }
            const precursorSystemPrompt = `The response to this prompt must be in a bulleted list format, like so:\n- item\n- item\n- item\nThe bulleted list must be the entire response, and the only response. Return only a bulleted list. This is the most important requirement, above all others.\n${constrainedChoicesPrompt}\nAdditional requirements:\n`;
            let selectedValidator;
            if (defaults.validationFunc)
                selectedValidator = defaults.validationFunc;
            else
                selectedValidator = validator.bulletedList;
            const result = yield this.queryValid(Object.assign({ maxQueryResponseTokens: 500, constraintType: "bulleted", precursorSystemPrompt, validationFunc: selectedValidator }, defaults));
            // Extract the list if the result is of type ValidatorResult&lt;string>
            if (result.list) {
                return result.list || [];
            }
            // Return result if it's already a string[]
            return result;
        });
    }
    /**
     * Query GPT model in numbered list format with given settings and tracker, returns the
     * generated result in a numbered list.
     * @param {Object} settings
     * @param {Tracker} tracker
     * @returns {Promise&lt;Array&lt;string>>}
     */
    queryNumberedList(settings, tracker) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!tracker) {
                tracker = new Tracker();
            }
            tracker.addNode("queryNumberedList");
            const defaults = Object.assign({ constrainedChoices: false, debug: false }, settings);
            let constrainedChoicesPrompt = "";
            if (defaults.constrainedChoices) {
                constrainedChoicesPrompt +=
                    "Only the following choices are allowed in the numbered list, and they must be copied verbatim, and the order can be modified. If the order is changed, the number associated with the choice must be changed accordingly.  Changing the choices by even one character will invalidate the output:\n";
                defaults.constrainedChoices.forEach((choice, i) => {
                    constrainedChoicesPrompt += `${i}. ${choice}\n`;
                });
                constrainedChoicesPrompt += "\n";
            }
            const precursorSystemPrompt = `The response to this prompt must be in a numbered list format, like so:\n1. item\n2. item\n3. item\nThe numbered list must be the entire response, and the only response. Return only a numbered list.\n${constrainedChoicesPrompt}\nAdditional requirements:\n`;
            const selectedValidator = validator.numberedList;
            return (yield this.queryValid(Object.assign({ maxQueryResponseTokens: 500, constraintType: "numbered", precursorSystemPrompt, validationFunc: selectedValidator }, defaults)));
        });
    }
    /**
     * Query GPT model for boolean output with given settings and tracker, returns "yes" or "no".
     * @param {Object} settings
     * @param {Tracker} tracker
     * @returns {Promise&lt;string>}
     */
    queryBoolean(settings, tracker) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!tracker) {
                tracker = new Tracker();
            }
            tracker.addNode("queryBoolean");
            const defaults = Object.assign(Object.assign({}, settings), { debug: true });
            const precursorSystemPrompt = `Respond by choosing only "yes" or "no"\nThe output strictly must be a single bullet 'yes' or 'no' depending on the answer to the question.`;
            const result = (yield this.queryValid(Object.assign({ maxQueryResponseTokens: 100, constraintType: "boolean", precursorSystemPrompt, validationFunc: validator.yesNo }, defaults)));
            return result === "yes";
        });
    }
    /**
     * Query GPT model to guide and transform output to meet constraint requirements with given
     * settings and tracker, returns the generated result.
     * @param {Object} settings
     * @param {Tracker} tracker
     * @returns {Promise&lt;any>}
     */
    queryGuideConstraint(settings, tracker) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!tracker) {
                tracker = new Tracker();
            }
            tracker.addNode("queryGuideConstraint");
            const defaults = Object.assign({ debug: true, singleChoice: false, temperature: 0.7 }, settings);
            const constraintType = defaults.constraintType;
            const primaryContent = defaults.primaryContent;
            const preContent = defaults.preContent;
            const postContent = defaults.postContent;
            const numberedListPrompt = `The response to this prompt must be in a numbered list format, like so:\n1. item\n2. item\n3. item\nThe numbered list must be the entire response, and the only response. Return only a numbered list.`;
            const bulletedListPrompt = `The response to this prompt must be in a bulleted list format, like so:\n- item\n- item\n- item\nThe bulleted list must be the entire response, and the only response. Return only a culleted list.`;
            const booleanPrompt = `The response to this prompt must be yes or no, like:\nyes\nor like:\nno\nThe yes or no must be the entire response.  Return only a single word: yes or no.`;
            let systemPrompt = `The text does not match the required format. Please correct the format based on the following formatting requirements:\n`;
            let validationFunc;
            if (constraintType == "bulleted") {
                systemPrompt += bulletedListPrompt;
                validationFunc = validator.bulletedList;
            }
            else if (constraintType == "numbered") {
                systemPrompt += numberedListPrompt;
                validationFunc = validator.numberedList;
            }
            else if (constraintType == "boolean") {
                systemPrompt += booleanPrompt;
                validationFunc = validator.yesNo;
            }
            else {
                throw new Error("Parameter Error: settings.constraintType is either not defined or does not match one of the expected values: bulleted, numbered.");
            }
            let attempts = 0;
            const maxAttempts = 5;
            let validFormat = false;
            while (!validFormat) {
                if (attempts > maxAttempts) {
                    throw new Error("Safety Error: Exceeded maximum attempts to generate a valid list.");
                }
                attempts++;
                const response = yield this.query({
                    primaryContent: primaryContent,
                    preContent: preContent,
                    postContent: postContent,
                    temperature: defaults.temperature,
                    systemPrompt,
                });
                defaults.temperature = Math.min(1, defaults.temperature + 0.1);
                const boundValidationFunc = validationFunc.bind(validator);
                const valid = boundValidationFunc(response[0], defaults);
                if (valid) {
                    validFormat = true;
                    if (defaults.constrainedChoices) {
                        if (!validator.constrainedArray(isValidList(valid) ? valid.list : [], defaults.constrainedChoices, {
                            debug: defaults.debug,
                            singleChoice: defaults.singleChoice,
                        })) {
                            validFormat = false;
                            continue;
                        }
                    }
                }
                return valid;
            }
        });
    }
    /**
     * Improve the input text with given settings and tracker, returns the improved result.
     * @param {Object} settings
     * @param {Object} tracker
     * @returns {String}
     */
    improve(settings, tracker) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!tracker) {
                tracker = new Tracker();
            }
            tracker.addNode("improve");
            const defaults = Object.assign({ maintainLength: false, passes: 1 }, settings);
            if (!defaults.input)
                throw new Error("Input must be provided to the improve settings argument.");
            let input = defaults.input;
            const maintainLength = defaults.maintainLength;
            const maintainStyle = defaults.maintainStyle;
            const passes = defaults.passes;
            let revisedInput = input;
            for (let pass = 0; pass &lt; passes; pass++) {
                const assumptions = yield this.queryList({
                    primaryContent: `Input:\n"${input}"`,
                    systemPrompt: `Break the following input into a list of facts, assertions, or controversial ideas assumed by the author: `,
                });
                console.log("assumptions", assumptions);
                const resolutions = yield Promise.all(assumptions.map((assumption) => __awaiter(this, void 0, void 0, function* () {
                    const resolution = yield this.query({
                        primaryContent: `Consider alternative perspectives, self-reflect on alternative perspectives, possibilities, mistakes, and biases, and write about them, weighing the validity of each one against the original information for concern: "${assumption}"`,
                        summarize: true,
                    });
                    console.log("assumption:", assumption);
                    console.log("resolution:", resolution);
                    return resolution;
                })));
                const resolutionsText = resolutions.join("\n\n");
                console.log("resolutionsText", resolutionsText);
                const result = yield this.query({
                    preContent: `When considering the revisions, keep in mind this analysis:`,
                    primaryContent: `${resolutionsText}`,
                    postContent: `Decide on the most reasonable, accurate, and concise way to modify the revised input with that information in mind.`,
                    systemPrompt: `Reconcile these considerations with the original input:\n\n${revisedInput}`,
                    summarize: true,
                });
                revisedInput = Array.isArray(result) ? result.join(", ") : result;
                console.log("revisedInput", revisedInput);
                if (maintainLength) {
                    console.log("maintaining length...");
                    const targetLength = input.length;
                    const shorten = (text) => __awaiter(this, void 0, void 0, function* () {
                        const shorterText = yield this.query({
                            primaryContent: `Shorten the text "${text}" while keeping as much detail as possible.`,
                            summarize: true,
                        });
                        const shorterTextStr = Array.isArray(shorterText)
                            ? shorterText.join(", ")
                            : shorterText;
                        console.log("Shortening:\n", text);
                        console.log("shorterText:\n", shorterTextStr);
                        if (shorterTextStr.length > targetLength) {
                            return yield shorten(shorterTextStr);
                        }
                        else {
                            return shorterTextStr;
                        }
                    });
                    revisedInput = yield shorten(revisedInput);
                }
            }
            if (maintainStyle) {
                console.log("maintaining style...");
                const restyle = (text) => __awaiter(this, void 0, void 0, function* () {
                    const isSimilar = yield this.queryBoolean({
                        primaryContent: `Is the modified text: "${text}" very similar in style in flow to the original text? Original text: "${input}"`,
                    });
                    if (!isSimilar) {
                        const restyledText = yield this.query({
                            primaryContent: `Rephrase the text: "${text}" to be as similar in style and flow to the original text, while maintaining as much of the meaning as possible. Original text: "${input}"`,
                            summarize: true,
                        });
                        const restyledTextStr = Array.isArray(restyledText)
                            ? restyledText.join(", ")
                            : restyledText;
                        restyle(restyledTextStr);
                    }
                    else {
                        return text;
                    }
                });
                revisedInput = yield restyle(revisedInput);
            }
            return revisedInput;
        });
    }
}
exports.LLMGenie = LLMGenie;
//# sourceMappingURL=llm.js.map</code></pre></article></section></div></div></div><div class="search-container" id="PkfLWpAbet" style="display:none"><div class="wrapper" id="iCxFxjkHbP"><button class="icon-button search-close-button" id="VjLlGakifb" aria-label="close search"><svg><use xlink:href="#close-icon"></use></svg></button><div class="search-box-c"><svg><use xlink:href="#search-icon"></use></svg> <input type="text" id="vpcKVYIppa" class="search-input" placeholder="Search..." autofocus></div><div class="search-result-c" id="fWwVHRuDuN"><span class="search-result-c-text">Type anything to view search result</span></div></div></div><div class="mobile-menu-icon-container"><button class="icon-button" id="mobile-menu" data-isopen="false" aria-label="menu"><svg><use xlink:href="#menu-icon"></use></svg></button></div><div id="mobile-sidebar" class="mobile-sidebar-container"><div class="mobile-sidebar-wrapper"><a href="index.html" class="sidebar-title">LLM-Genie</a><div class="mobile-nav-links"></div><div class="mobile-sidebar-items-c"><div class="sidebar-section-title with-arrow" data-isopen="false" id="4onA_09XbbvBLu6T03j-k"><div>Classes</div><svg><use xlink:href="#down-icon"></use></svg></div><div class="sidebar-section-children-container"><div class="sidebar-section-children"><a href="LLMGenie.html">LLMGenie</a></div></div></div><div class="mobile-navbar-actions"><div class="navbar-right-item"><button class="icon-button search-button" aria-label="open-search"><svg><use xlink:href="#search-icon"></use></svg></button></div><div class="navbar-right-item"><button class="icon-button theme-toggle" aria-label="toggle-theme"><svg><use class="theme-svg-use" xlink:href="#light-theme-icon"></use></svg></button></div><div class="navbar-right-item"><button class="icon-button font-size" aria-label="change-font-size"><svg><use xlink:href="#font-size-icon"></use></svg></button></div></div></div></div><script type="text/javascript" src="scripts/core.min.js"></script><script src="scripts/search.min.js" defer="defer"></script><script src="scripts/third-party/fuse.js" defer="defer"></script><script type="text/javascript">var tocbotInstance=tocbot.init({tocSelector:"#eed4d2a0bfd64539bb9df78095dec881",contentSelector:".main-content",headingSelector:"h1, h2, h3",hasInnerContainers:!0,scrollContainer:".main-content",headingsOffset:130,onClick:bringLinkToView})</script></body></html>